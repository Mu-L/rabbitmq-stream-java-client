= RabbitMQ Stream Java Client
:revnumber: {project-version}
:revremark: {build-number}
:example-caption!:
ifndef::imagesdir[:imagesdir: images]
ifndef::sourcedir[:sourcedir: ../../main/java]
:source-highlighter: prettify
:test-examples: ../../test/java/com/rabbitmq/stream/docs

The RabbitMQ Stream Java Client is a Java library to communicate with
the https://github.com/rabbitmq/rabbitmq-stream[RabbitMQ Stream Plugin].
It allows creating and delete streams, as well as to publish to and consume from
these streams.

== What is a RabbitMQ Stream?

A RabbitMQ stream is a persistent and replicated data structure that models
an https://en.wikipedia.org/wiki/Append-only[append-only log]. It differs from the classical
RabbitMQ queue in the way message consumption works. In a classical RabbitMQ queue,
consuming removes messages from the queue. In a RabbitMQ stream, consuming leaves
the stream intact. So the content of a stream can be read and re-read without
impact or destructive effect.

None of the stream or classical queue data structure is better than the other,
they are usually suited for different use cases.

== When to Use RabbitMQ Stream?

A stream abstraction is useful when one or several consumer applications
require the whole history of data ("replay").

Streams can also be useful when a higher throughput than with classical
RabbitMQ queues is required. RabbitMQ streams use various optimization techniques,
and a custom network protocol to achieve performances that are not possible
with the other protocols supported in RabbitMQ (AMQP, STOMP, MQTT). This
does not make the stream protocol better than these protocols, they just
all serve different purposes.

== Other Way to Use Streams in RabbitMQ

It is also possible to use the stream abstraction in RabbitMQ
with the AMQP 0-9-1 protocol. Instead of consuming from a stream
with the stream protocol, one consumes from a "stream-powered" queue with
the AMQP 0-9-1 protocol. A "stream-powered" queue is a special type of queue that
is backed up with a stream infrastructure layer and adapted to
provide the stream semantics (mainly non-destructive reading).

Using such a queue has the advantage to provide the features
inherent to the stream abstraction (append-only structure, non-destructive
reading) with any AMQP 0-9-1 client library. This is clearly
interesting when considering the maturity of AMQP 0-9-1 client libraries
and the ecosystem around AMQP 0-9-1.

But by using it, one does not benefit from the performance
of the stream protocol, which has been designed for performance in mind,
whereas AMQP 0-9-1 is a more general-purpose protocol.

It is not possible to use "stream-powered" queues with the stream Java client,
you need to use an AMQP 0-9-1 client library.

== Guarantees

RabbitMQ stream provides at-least-once guarantees thanks to the
publisher confirm mechanism, which is supported by the stream Java client.

== The Stream Java Client

The library requires Java 8 or more.

=== Setting up RabbitMQ

A RabbitMQ node with the stream plugin enabled is required. The easiest way
to get up and running is to use Docker. It is also possible to use the
generic Unix package.

==== With Docker

The following command creates a one-time Docker container to run RabbitMQ
with the stream plugin enabled:

.Running the stream plugin with Docker
----
docker run -it --rm --name rabbitmq -p 5555:5555 pivotalrabbitmq/rabbitmq-stream
----

The previous command exposes only the stream port (5555), you can expose
ports for other protocols:

.Exposing the AMQP 0.9.1 and management ports:
----
docker run -it --rm --name rabbitmq -p 5555:5555 -p 5672:5672 -p 15672:15672 \
    pivotalrabbitmq/rabbitmq-stream
----

Refer to the official https://hub.docker.com/_/rabbitmq[RabbitMQ Docker image web page]
to find out more about its usage. Make sure to use the `pivotalrabbitmq/rabbitmq-stream`
image in the command line.

The `pivotalrabbitmq/rabbitmq-stream` Docker image is meant for development usage only. It does not
support all the features of the official Docker image, like TLS.

==== With the Generic Unix Package

The generic Unix package requires https://www.rabbitmq.com/which-erlang.html[Erlang] to be installed.

* Download the https://bintray.com/rabbitmq/all-dev/rabbitmq-stream[latest generic Unix alpha from Bintray].
* Follow the https://www.rabbitmq.com/install-generic-unix.html[instructions to install the generic Unix package].
* Enable the plugin `./rabbitmq-plugins enable rabbitmq_stream`.
* Start the broker `./rabbitmq-server -detached`. This starts the stream listener on port 5555.

=== Dependencies

Use your favorite build management tool to add the client dependencies to your project.

Note the client uses the https://github.com/apache/qpid-proton-j[Apache QPid Proton-J]
library for <<working-with-complex-messages,AMQP 1.0 message encoding and decoding>>.

==== Maven

.pom.xml
[source,xml,subs="attributes,specialcharacters"]
----
<dependencies>

  <dependency>
    <groupId>com.rabbitmq</groupId>
    <artifactId>stream-client</artifactId>
    <version>{project-version}</version>
  </dependency>

  <dependency>
    <groupId>org.apache.qpid</groupId>
    <artifactId>proton-j</artifactId>
    <version>{protonj-version}</version>
  </dependency>

</dependencies>

<repositories>

  <repository>
    <id>ossrh</id>
    <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    <snapshots><enabled>true</enabled></snapshots>
    <releases><enabled>false</enabled></releases>
  </repository>

</repositories>
----

==== Gradle

.build.gradle
[source,groovy,subs="attributes,specialcharacters"]
----
dependencies {
  compile "com.rabbitmq:stream-client:{project-version}"
  compile "org.apache.qpid:proton-j:{protonj-version}"
}

repositories {
  maven { url 'https://oss.sonatype.org/content/repositories/snapshots' }
  mavenCentral()
}
----

=== Sample Application

This section covers the basics of the RabbitMQ Stream Java API by building
a small publish/consume application. This is a good way to get
an overview of the API. If you want a more comprehensive introduction,
you can go to the <<rabbitmq-stream-java-api,the reference documentation section>>.

The sample application publishes some messages and then registers
a consumer to make some computations out of them. The
https://github.com/rabbitmq/rabbitmq-stream-java-client/blob/master/src/test/java/com/rabbitmq/stream/docs/SampleApplication.java[source code is available on GitHub].

The sample class starts with a few imports:

.Imports for the sample application
[source,java,indent=0]
--------
include::{test-examples}/SampleApplication.java[tag=sample-imports]
--------

The next step is to create the `Environment`. It is a management object
used to manage streams and create producers as well as consumers. The
next snippet shows how to create an `Environment` instance and
create the stream used in the application:

.Creating the environment
[source,java,indent=0]
--------
include::{test-examples}/SampleApplication.java[tag=sample-environment]
--------
<1> Use `Environment#builder` to create the environment
<2> Create the stream

Then comes the publishing part. The next snippet shows how to create
a `Producer`, send messages, and handle publishing confirmations, to
make sure the broker has taken outbound messages into account.
The application uses a count down latch to move on once the messages
have been confirmed.

.Publishing messages
[source,java,indent=0]
--------
include::{test-examples}/SampleApplication.java[tag=sample-publisher]
--------
<1> Create the `Producer` with `Environment#producerBuilder`
<2> Send messages with `Producer#send(Message, ConfirmationHandler)`
<3> Create a message with `Producer#messageBuilder`
<4> Count down on message publishing confirmation
<5> Wait for all publishing confirmations to have arrived
<6> Close the producer

It is now time to consume the messages. The `Environment` lets us create a `Consumer`
and provide some logic on each incoming message by implementing a `MessageHandler`.
The next snippet does this to calculate a sum and output it once all the messages
have been received:

.Consuming messages
[source,java,indent=0]
--------
include::{test-examples}/SampleApplication.java[tag=sample-consumer]
--------
<1> Create the `Consumer` with `Environment#consumerBuilder`
<2> Set up the logic to handle messages
<3> Add the value in the message body to the sum
<4> Count down on each message
<5> Wait for all messages to have arrived
<6> Output the sum
<7> Close the consumer

The application has some cleaning to do before terminating, that is
deleting the stream and closing the environment:

.Cleaning before terminating
[source,java,indent=0]
--------
include::{test-examples}/SampleApplication.java[tag=sample-environment-close]
--------
<1> Delete the stream
<2> Close the environment

You can run the sample application from the root of the project (you need
a running local RabbitMQ node with the stream plugin enabled):

----
$ ./mvnw -q test-compile exec:java -Dexec.classpathScope="test" \
    -Dexec.mainClass="com.rabbitmq.stream.docs.SampleApplication"
Starting publishing...
Published 10000 messages
Starting consuming...
Sum: 49995000
----

You can remove the `-q` flag if you want more insight on the execution of the build.

=== RabbitMQ Stream Java API

==== Overview

This section describes the API to connect to the RabbitMQ Stream Plugin, publish messages, and
consume messages. There are 3 main interfaces:

 * `com.rabbitmq.stream.Environment` for connecting to a node and optionally
managing streams.
 * `com.rabbitmq.stream.Producer` to publish messages.
 * `com.rabbitmq.stream.Consumer` to consume messages.

==== Environment

===== Creating the Environment

The environment is the main entry point to a node or a cluster of nodes. `Producer` and
`Consumer` instances are created from an `Environment` instance. Here is the simplest
way to create an `Environment` instance:

.Creating an environment with all the defaults
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=environment-creation]
--------
<1> Create an environment that will connect to localhost:5555
<2> Close the environment after usage

Note the environment must be closed to release resources when it is no
longer needed.

Consider the environment like a long-lived object. An application will usually
create one `Environment` instance when it starts up and close it when it exits.

It is possible to use a URI to specify all the necessary information to
connect to a node:

.Creating an environment with a URI
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=environment-creation-with-uri]
--------
<1> Use the `uri` method to specify the URI to connect to

The previous snippet uses a URI that specifies the following information: host, port,
username, password, and virtual host (`/`, which is encoded as `%2f`).
The URI follows the same rules as the
https://www.rabbitmq.com/uri-spec.html[AMQP 0.9.1 URI],
except the protocol must be `rabbitmq-stream` and TLS is not supported.

When using one URI, the corresponding node will be the main entry point to connect to. The
`Environment` will then use the stream protocol to find out more about streams topology
(leaders and replicas) when asked to create `Producer`s and `Consumer`s. The `Environment`
may become blind if this node goes down though, so it may be more appropriate to specify
several other URIs to try in case of failure of a node:

.Creating an environment with several URIs
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=environment-creation-with-uris]
--------
<1> Use the `uris` method to specify several URIs

By specifying several URIs, the environment will try to connect to the first one, and
will pick a new URI randomly in case of disconnection.

The following table sums up the main settings to create a `Environment`:

[%header,cols=3*]
|===
|Parameter Name
|Description
|Default

|`uri`
|The URI of the node to connect to (single node).
|`rabbitmq-stream://guest:guest@localhost:5555/%2f`

|`uris`
|The URI of the nodes to try to connect to (cluster).
|`rabbitmq-stream://guest:guest@localhost:5555/%2f` singleton list

|`host`
|Host to connect to.
|`localhost`

|`port`
|Port to use.
|`5555`

|`username`
|Username to use to connect.
|`guest`

|`password`
|Password to use to connect.
|`guest`

|`virtualHost`
|Virtual host to connect to.
|`/`

|`recoveryBackOffDelayPolicy`
|Delay policy to use for backoff on connection recovery.
|Fixed delay of 5 seconds
|===

===== Managing Streams

Streams are usually long-lived, centrally-managed entities, that is, applications
are not supposed to create and delete them. It is nevertheless possible to create and
delete stream with the `Environment`. This comes in handy for development and testing
purposes.

Streams are created with the `Environment#streamCreator()` method:

.Creating a stream
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=stream-creation]
--------
<1> Create the `my-stream` stream

Streams can be deleted with the `Environment#delete(String)` method:

.Deleting a stream
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=stream-deletion]
--------
<1> Delete the `my-stream` stream

Note you should avoid stream churn (creating and deleting streams repetitively)
as their creation and deletion imply some significant housekeeping on
the server side (interactions with the file system, communication between nodes of the cluster).

[[limiting-the-size-of-a-stream]]It is also possible to limit the size of a stream
when creating it. A stream
is an append-only data structure and reading from it does not remove data.
This means a stream can grow indefinitely. RabbitMQ Stream supports a
size-based retention policy: once the stream reaches a given size,
it is truncated (starting from the beginning).

[IMPORTANT]
.Limit the size of streams if appropriate!
====
Make sure to set up a retention policy on potentially large streams
if you don't want to saturate the storage devices of your servers. Keep
in mind that this means some data will be erased!
====

It is possible to set up the retention policy when creating the stream:

.Setting the retention policy when creating a stream
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=stream-creation-retention]
--------
<1> Set the maximum size to 10 GB
<2> Set the segment size to 500 MB

The previous snippet mentions a segment size. RabbitMQ Stream does not store a stream
in a big, single file, it uses segment files for technical reasons.
A stream is truncated by deleting whole segment files (and not part of them),
so the maximum size of a stream is usually significantly higher than the size of
segment files. 500 MB is a reasonable segment file size to begin with.

==== Producer

===== Creating a Producer

A `Producer` instance is created from the `Environment`. The only mandatory
setting to specify is the stream to publish to:

.Creating a producer from the environment
[source,java,indent=0]
--------
include::{test-examples}/ProducerUsage.java[tag=producer-creation]
--------
<1> Use `Environment#producerBuilder()` to define the producer
<2> Specify the stream to publish to
<3> Create the producer instance with `build()`
<4> Close the producer after usage

Consider a `Producer` instance like a long-lived object, do not create one
to send just one message.

Internally, the `Environment` will query the broker to find out about
the topology of the stream and will create or re-use a connection to
publish to the leader node of the stream.

The following table sums up the main settings to create a `Producer`:

[%header,cols=3*]
|===
|Parameter Name
|Description
|Default

|`batchSize`
|The maximum number of messages to accumulate before sending them to the broker.
|100

|`subEntrySize`
|The number of messages to put in a sub-entry. A sub-entry is one "slot" in a publishing
frame, meaning outbound messages are not only batched in publishing frames, but in sub-entries
as well. Use this feature to increase throughput at the cost of increased latency.
|1 (meaning no use of sub-entry batching)

|`maxUnconfirmedMessages`
|The maximum number of unconfirmed outbound messages. `Producer#send` will start
blocking when the limit is reached.
|10,000

|`batchPublishingDelay`
|Period to send a batch of messages.
|100 ms
|===

===== Sending Messages

Once a `Producer` has been created, it is possible to send a message with
the `Producer#send(Message, ConfirmationHandler)` method. The following
snippet shows how to publish a message with a byte array payload:

.Sending a message
[source,java,indent=0]
--------
include::{test-examples}/ProducerUsage.java[tag=producer-publish]
--------
<1> The payload of a message is an array of bytes
<2> Create the message with `Producer#messageBuilder()`
<3> Define the behavior on publish confirmation

Messages are not only made of a `byte[]` payload, we will see in
<<working-with-complex-messages,the next section>>
they can also carry pre-defined and application properties.

The `ConfirmationHandler` defines an asynchronous callback invoked
when the client received from the broker the confirmation the message
has been taken into account. The `ConfirmationHandler` is the place
for any logic on publishing confirmation, including
re-publishing the message if it is negatively acknowledged.

===== Working with Complex Messages

The publishing example above showed that messages are made of
a byte array payload, but it did not go much further. Messages in RabbitMQ Stream
can actually be more sophisticated, as they comply to the
https://www.amqp.org/resources/specifications[AMQP 1.0 message format].

In a nutshell, a message in RabbitMQ Stream has the following structure:

* properties: _a defined set of standard properties of the message_ (e.g.
message ID, correlation ID, content type, etc).
* application properties: a set of arbitrary key/value pairs.
* body: typically an array of bytes.
* message annotations: a set of key/value pairs (aimed at the infrastructure).

The RabbitMQ Stream Java client uses the `Message` interface to abstract
a message and the recommended way to create `Message` instances is to
use the `Producer#messageBuilder()` method. To publish a `Message`, use
the `Producer#send(Message,ConfirmationHandler)`:

.Creating a message with properties
[source,java,indent=0]
--------
include::{test-examples}/ProducerUsage.java[tag=producer-publish-complex-message]
--------
<1> Get the message builder from the producer
<2> Get the properties builder and set some properties
<3> Go back to message builder
<4> Set byte array payload
<5> Build the message instance
<6> Publish the message

[NOTE]
.Is RabbitMQ Stream based on AMQP 1.0?
====
AMQP 1.0 is a standard that defines _an efficient binary peer-to-peer
protocol for transporting messages between two processes over a network_.
It also defines _an abstract message format, with concrete standard encoding_.
This is only the latter part that RabbitMQ Stream uses. The AMQP 1.0 protocol is not used,
only AMQP 1.0 encoded messages are wrapped into the RabbitMQ Stream binary protocol.

The actual AMQP 1.0 message encoding and decoding happen on the client side, the
RabbitMQ Stream plugin stores only bytes, it has no idea that AMQP 1.0 message format
is used.

AMQP 1.0 message format was chosen because of its flexibility and its advanced
type system. It provides good interoperability, which allows streams
to be accessed as AMQP 0-9-1 queues, without data loss.
====

==== Consumer

A `Consumer` instance is created with `Environment#consumerBuilder()`. The main
settings are the stream to consume from, the place in the stream to start
consuming from (the _offset_), and a callback when a message is received
(the `MessageHandler`). The next snippet shows how to create a `Consumer`:

.Creating a consumer
[source,java,indent=0]
--------
include::{test-examples}/ConsumerUsage.java[tag=producer-creation]
--------
<1> Use `Environment#consumerBuilder()` to define the consumer
<2> Specify the stream to consume from
<3> Specify where to start consuming from
<4> Define behavior on message consumption
<5> Build the consumer
<6> Close consumer after usage

The broker start sending messages as soon as the `Consumer` instance is created.

The possible values for the offset parameter are the following:

* `OffsetSpecification.first()`: starting from the first available offset. If
the stream has not been <<limiting-the-size-of-a-stream,truncated>>, this
means the beginning of the stream (offset 0).
* `OffsetSpecification.last()`: starting from the end of the stream and returning
the last chunk of messages immediately (if the stream is not empty).
* `OffsetSpecification.next()`: starting from the next offset to be written. Contrary
to `OffsetSpecification.last()`, consuming with `OffsetSpecification.next()`
will not return anything if no-one is publishing to the stream. The broker will start
sending messages to the consumer when messages are published to the stream.
* `OffsetSpecification.offset(offset)`: starting from the specified offset. 0 means consuming
from the beginning of the stream (first messages). The client
can also specify any number, for example the offset where it left off
in a previous incarnation of the application.
* `OffsetSpecification.timestamp(timestamp)`: starting from the messages stored
after the specified timestamp.

=== Builing the Client

You need JDK 1.8 or more installed.

To build the JAR file:

----
./mvnw clean package -DskipITs -DskipTests
----

To launch the test suite (requires a local RabbitMQ node with stream plugin enabled):

----
./mvnw verify
----

== The Performance Tool

The library contains also a performance tool to test the RabbitMQ Stream plugin.
It is https://bintray.com/rabbitmq/java-tools-dev/stream-perf-test[downloadable from Bintray]
as an uber JAR and can be built separately as well.

=== Using the Performance Tool

To launch a run:

----
$ java -jar stream-perf-test-{version}.jar
10:11:54.324 [main] INFO  c.r.stream.perf.StreamPerfTest - Created stream stream1
10:11:54.385 [main] INFO  c.r.stream.perf.StreamPerfTest - Producer will stream stream1
10:11:54.387 [main] INFO  c.r.stream.perf.StreamPerfTest - Starting consuming on stream1
10:11:54.390 [main] INFO  c.r.stream.perf.StreamPerfTest - Starting producer
1, published 155230 msg/s, confirmed 147824 msg/s, consumed 124487 msg/s, latency min/median/75th/95th/99th 1121/8225/17647/62468/73991 µs, chunk size 109
2, published 359193 msg/s, confirmed 336535 msg/s, consumed 306748 msg/s, latency min/median/75th/95th/99th 1398/56590/80607/127818/135925 µs, chunk size 345
3, published 523429 msg/s, confirmed 509044 msg/s, consumed 478710 msg/s, latency min/median/75th/95th/99th 1478/29996/69536/111946/135079 µs, chunk size 529
4, published 599735 msg/s, confirmed 594707 msg/s, consumed 568315 msg/s, latency min/median/75th/95th/99th 964/21032/52977/98643/133399 µs, chunk size 548
5, published 632114 msg/s, confirmed 609804 msg/s, consumed 591426 msg/s, latency min/median/75th/95th/99th 964/34303/74318/110684/127440 µs, chunk size 588
6, published 619328 msg/s, confirmed 618229 msg/s, consumed 598410 msg/s, latency min/median/75th/95th/99th 964/45918/86391/114714/138207 µs, chunk size 657
^C
Summary: published 641792 msg/s, confirmed 635240 msg/s, consumed 636256 msg/s, latency 95th 112730 µs, chunk size 711
----

The previous command will start publishing to and consuming from a stream created
only for the test. The tool outputs live metrics on the console and write more
detailed metrics in a `stream-perf-test-current.txt` file that get renamed to
`stream-perf-test-yyyy-MM-dd-HHmmss.txt` when the run ends.

To see the options:

----
java -jar stream-perf-test-{version}.jar --help
----

The performance tool comes also with a completion script. You can download it and enable it in
your `~/.zshrc` file:

----
alias stream-perf-test='java -jar target/stream-perf-test.jar'
source ~/.zsh/stream-perf-test_completion
----

Note the activation requires an alias which must be `stream-perf-test`. The command can be anything
though.

=== Building the Performance Tool

To build the uber JAR:

----
./mvnw clean package -Dmaven.test.skip -P performance-tool
----

Then run the tool:

----
java -jar target/stream-perf-test.jar
----