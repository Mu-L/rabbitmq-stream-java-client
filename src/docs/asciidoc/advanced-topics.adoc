:test-examples: ../../test/java/com/rabbitmq/stream/docs

== Advanced Topics

=== Filtering

WARNING: Filtering requires *RabbitMQ 3.13* or more.

RabbitMQ Stream's server-side filtering saves network bandwidth by filtering messages on the server, so clients receive only a subset of the messages in a stream.

The filtering feature works as follows:

* each message is published with an associated _filter value_
* a consumer that wants to enable filtering must:
** define one or several filter values
** define some client-side filtering logic

Why is client-side filtering logic still needed?
Server-side filtering is probabilistic â€” it may still send messages that don't match your filter values.
The server uses a https://en.wikipedia.org/wiki/Bloom_filter[Bloom filter] (a space-efficient probabilistic data structure) where false positives are possible.
Despite this limitation, filtering significantly reduces network bandwidth.

==== Filtering on the Publishing Side

Publishers must define logic to extract filter values from messages.
The following snippet shows how to extract the filter value from an application property:

.Declaring a producer with logic to extract a filter value from each message
[source,java,indent=0]
--------
include::{test-examples}/FilteringUsage.java[tag=producer-simple]
--------
<1> Extract filter value from `state` application property

Filter values can be null, resulting in _unfiltered_ messages that are published normally.

==== Filtering on the Consuming Side

A consumer needs to set up one or several filter values and some filtering logic to enable filtering.
The filtering logic must be consistent with the filter values.
In the next snippet, the consumer wants to process only messages from the state of California.
It sets a filter value to `california` and a predicate that accepts a message only if the `state` application property is `california`:

.Declaring a consumer with a filter value and filtering logic
[source,java,indent=0]
--------
include::{test-examples}/FilteringUsage.java[tag=consumer-simple]
--------
<1> Set filter value
<2> Set filtering logic

The filter logic is a `Predicate<Message>`.
It must return `true` if a message is accepted, following the same semantics as `java.util.stream.Stream#filter(Predicate)`.

As stated above, not all messages must have an associated filter value.
Many applications may not need filtering, so they can publish messages the regular way.
So a stream can contain messages with and without an associated filter value.

By default, messages without a filter value (a.k.a _unfiltered_ messages) are not sent to a consumer that enabled filtering.

But what if a consumer wants to process messages with a filter value and messages without any filter value as well?
It must use the `matchUnfiltered()` method in its declaration and also make sure to keep the filtering logic consistent:

.Getting unfiltered messages as well when enabling filtering
[source,java,indent=0]
--------
include::{test-examples}/FilteringUsage.java[tag=consumer-match-unfiltered]
--------
<1> Request messages from California
<2> Request messages without a filter value as well
<3> Let both types of messages pass

In the example above, the filtering logic allows both `california` messages _and_ messages without a state set as well.

==== Considerations on Filtering

Since the server may send non-matching messages due to the probabilistic nature of Bloom filters, the client-side filtering logic must be robust to avoid processing unwanted messages.

**Good filter value candidates:**

* Shared categorical values: geographical locations (countries, states), document types (payslip, invoice, order), product categories (book, luggage, toy)
* Values with reasonable cardinality (few to few thousand distinct values)

**Poor filter value candidates:**

* Unique identifiers (message IDs, timestamps, UUIDs)
* Values with extreme cardinality (tens of thousands of distinct values)

=== OAuth 2 Support

The client supports OAuth 2 authentication using the https://tools.ietf.org/html/rfc6749#section-4.4[OAuth 2 Client Credentials flow].
Both the client and RabbitMQ server must be configured to use the same OAuth 2 server.

**Prerequisites:**

* https://www.rabbitmq.com/docs/oauth2[OAuth 2 plugin] enabled on RabbitMQ
* OAuth 2 server (e.g. https://github.com/cloudfoundry/uaa[UAA]) configured and accessible

Token retrieval is configured at the environment level:

.Configuring OAuth 2 token retrieval
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=oauth2]
--------
<1> Access the OAuth 2 configuration
<2> Set the token endpoint URI
<3> Authenticate the client application
<4> Use Client Credentials grant type for service-to-service authentication
<5> Set optional parameters (depends on the OAuth 2 server)
<6> Set the SSL context (e.g. to verify and trust the identity of the OAuth 2 server)

The environment handles token management automatically:

* Retrieves tokens for stream connections
* Refreshes tokens before expiration
* Re-authenticates existing connections to prevent broker disconnections
* Uses the same token for all maintained connections

=== Using Native `epoll`

The stream Java client uses https://netty.io/[Netty]'s Java NIO transport by default, which works well for most applications.

For specialized performance requirements, Netty supports https://netty.io/wiki/native-transports.html[JNI-based transports].
These are less portable but may offer better performance for specific workloads.
Note: The RabbitMQ team has not observed significant improvements in their testing.

This example shows how to configure the popular https://en.wikipedia.org/wiki/Epoll[Linux `epoll` transport].
Other JNI transports follow the same configuration pattern.

Add the native transport dependency matching your OS and architecture.
This example uses Linux x86-64 with the `linux-x86_64` classifier.
Here is the declaration for Maven:

.Declaring the Linux x86-64 native `epoll` transport dependency with Maven
[source,xml,subs="attributes,specialcharacters"]
----
<dependencies>

  <dependency>
    <groupId>io.netty</groupId>
    <artifactId>netty-transport-native-epoll</artifactId>
    <version>{netty-version}</version>
    <classifier>linux-x86_64</classifier>
  </dependency>

</dependencies>
----

And for Gradle:

.Declaring the Linux x86-64 native `epoll` transport dependency with Gradle
[source,groovy,subs="attributes,specialcharacters"]
----
dependencies {
  compile "io.netty:netty-transport-native-epoll:{netty-version}:linux-x86_64"
}
----

The native `epoll` transport is set up when the environment is configured:

.Configuring the native `epoll` transport in the environment
[source,java,indent=0]
--------
include::{test-examples}/EnvironmentUsage.java[tag=native-epoll]
--------
<1> Create the `epoll` event loop group (don't forget to close it!)
<2> Use the Netty configuration helper
<3> Set the event loop group
<4> Set the channel class to use

Note the event loop group must be closed explicitly: the environment will not close it itself as it is provided externally.
